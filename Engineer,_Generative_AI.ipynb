{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "700YZDatiGFV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import vgg19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Load and preprocess the content and style images\n",
        "def load_and_preprocess_img(image_path, target_size=(224, 224)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "# Load your images\n",
        "content_image_path = 'path_to_your_content_image.jpg'\n",
        "style_image_path = 'path_to_your_style_image.jpg'\n",
        "content_image = load_and_preprocess_img(content_image_path)\n",
        "style_image = load_and_preprocess_img(style_image_path)\n",
        "\n",
        "# Step 2: Define the model\n",
        "# Load the VGG19 model with weights pre-trained on ImageNet\n",
        "model = vgg19.VGG19(include_top=False, weights='imagenet')\n",
        "\n",
        "# Define the layers we'll need\n",
        "output_layers = {\n",
        "    'content': 'block5_conv2',  # Content layer\n",
        "    'style': ['block1_conv1',   # Style layers\n",
        "              'block2_conv1',\n",
        "              'block3_conv1',\n",
        "              'block4_conv1',\n",
        "              'block5_conv1']\n",
        "}\n",
        "\n",
        "# Create models for content and style features\n",
        "content_model = Model(inputs=model.input, outputs=model.get_layer(output_layers['content']).output)\n",
        "style_models = [Model(inputs=model.input, outputs=model.get_layer(layer).output) for layer in output_layers['style']]\n",
        "\n",
        "# Step 3: Define the loss functions\n",
        "def content_loss(content, combination):\n",
        "    return tf.reduce_sum(tf.square(combination - content))\n",
        "\n",
        "def gram_matrix(input_tensor):\n",
        "    features = tf.reshape(input_tensor, (-1, input_tensor.shape[3]))\n",
        "    gram = tf.matmul(features, tf.transpose(features))\n",
        "    return gram\n",
        "\n",
        "def style_loss(style, combination):\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = style_image.shape[1] * style_image.shape[2]\n",
        "    return tf.reduce_sum(tf.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
        "\n",
        "# Step 4: Training loop\n",
        "def compute_loss_and_grads(content_image, style_image, combination_image):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Extract features of the content, style, and combination images\n",
        "        content_features = content_model(content_image)\n",
        "        style_features = [model(style_image) for model in style_models]\n",
        "        combination_features = content_model(combination_image)\n",
        "        comb_style_features = [model(combination_image) for model in style_models]\n",
        "\n",
        "        # Initialize the loss\n",
        "        loss = tf.zeros(shape=())\n",
        "\n",
        "        # Add content loss\n",
        "        loss += content_loss(content_features, combination_features) * content_weight\n",
        "\n",
        "        # Add style loss\n",
        "        for comb_feat, style_feat in zip(comb_style_features, style_features):\n",
        "            loss += (style_loss(style_feat, comb_feat) * style_weight) / len(output_layers['style'])\n",
        "\n",
        "    # Compute gradients\n",
        "    grads = tape.gradient(loss, combination_image)\n",
        "    return loss, grads\n",
        "\n",
        "# Step 5: Optimization\n",
        "def style_transfer(content_image, style_image, num_iterations=10):\n",
        "    combination_image = tf.Variable(content_image, dtype=tf.float32)\n",
        "    optimizer = tf.optimizers.Adam(learning_rate=5.0)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        loss, grads = compute_loss_and_grads(content_image, style_image, combination_image)\n",
        "        optimizer.apply_gradients([(grads, combination_image)])\n",
        "        if i % 1 == 0:\n",
        "            print(f'Iteration {i}: loss={loss}')\n",
        "            img = deprocess_img(combination_image.numpy())\n",
        "            plt.imshow(img)\n",
        "            plt.show()\n",
        "\n",
        "# Step 6: Run the style transfer\n",
        "style_transfer(content_image, style_image, num_iterations=10)\n",
        "\n",
        "# Utility function to convert a tensor into a valid image\n",
        "def deprocess_img(processed_img):\n",
        "    x = processed_img.copy()\n",
        "    if len(x.shape) == 4:\n",
        "        x = np.squeeze(x, 0)\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n"
      ]
    }
  ]
}